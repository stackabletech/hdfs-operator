---
apiVersion: kuttl.dev/v1beta1
kind: TestStep
metadata:
  name: install-hdfs
timeout: 180
---
apiVersion: hdfs.stackable.tech/v1alpha1
kind: HdfsCluster
metadata:
  name: hdfs
spec:
  image:
{% if test_scenario['values']['hadoop'].find(",") > 0 %}
    custom: "{{ test_scenario['values']['hadoop'].split(',')[1] }}"
    productVersion: "{{ test_scenario['values']['hadoop'].split(',')[0] }}"
{% else %}
    productVersion: "{{ test_scenario['values']['hadoop'] }}"
{% endif %}
    pullPolicy: IfNotPresent
  clusterConfig:
    zookeeperConfigMapName: hdfs-zk
    dfsReplication: 1
{% if lookup('env', 'VECTOR_AGGREGATOR') %}
    vectorAggregatorConfigMapName: vector-aggregator-discovery
{% endif %}
  nameNodes:
    envOverrides:
      COMMON_VAR: role-value # overridden by role group below
      ROLE_VAR: role-value   # only defined here at role level
      HDFS_NAMENODE_OPTS: >
        -Djava.security.properties=/stackable/config/namenode/security.properties
        -javaagent:/stackable/jmx/jmx_prometheus_javaagent.jar=8183:/stackable/jmx-exporter-config/namenode.yaml
        -Xmx838860k
    podOverrides:
      spec:
        initContainers:
          - name: format-namenodes
            volumeMounts:
              - name: jmx-exporter-config
                mountPath: /stackable/jmx-exporter-config
        containers:
          - name: namenode
            volumeMounts:
              - name: jmx-exporter-config
                mountPath: /stackable/jmx-exporter-config
        volumes:
          - name: jmx-exporter-config
            configMap:
              name: jmx-exporter-config
    config:
      listenerClass: {{ test_scenario['values']['listener-class'] }}
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
    roleGroups:
      default:
        replicas: 2
        envOverrides:
          COMMON_VAR: group-value # overrides role value
          GROUP_VAR: group-value # only defined here at group level
  dataNodes:
    envOverrides:
      COMMON_VAR: role-value # overridden by role group below
      ROLE_VAR: role-value   # only defined here at role level
      HDFS_DATANODE_OPTS: >
        -Djava.security.properties=/stackable/config/datanode/security.properties
        -javaagent:/stackable/jmx/jmx_prometheus_javaagent.jar=8082:/stackable/jmx-exporter-config/datanode.yaml
        -Xmx419430k
    podOverrides:
      spec:
        containers:
          - name: datanode
            volumeMounts:
              - name: jmx-exporter-config
                mountPath: /stackable/jmx-exporter-config
        volumes:
          - name: jmx-exporter-config
            configMap:
              name: jmx-exporter-config
    config:
      listenerClass: {{ test_scenario['values']['listener-class'] }}
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
{% if test_scenario['values']['datanode-pvcs'] == '2hdd-1ssd' %}
      resources:
        storage:
          data: # We need to overwrite the data pvcs coming from the default value
            count: 0
          hdd:
            capacity: 2Gi
            count: 2
            hdfsStorageType: Disk
          ssd:
            capacity: 1Gi
            # storageClass: premium # We can't set the storage class in itegration tests, as we don't know which ones are available
            count: 1
            hdfsStorageType: SSD
{% endif %}
    roleGroups:
      default:
        envOverrides:
          COMMON_VAR: group-value # overrides role value
          GROUP_VAR: group-value # only defined here at group level
        replicas: {{ test_scenario['values']['number-of-datanodes'] }}
  journalNodes:
    envOverrides:
      COMMON_VAR: role-value # overridden by role group below
      ROLE_VAR: role-value   # only defined here at role level
      HDFS_JOURNALNODE_OPTS: >
        -Djava.security.properties=/stackable/config/journalnode/security.properties
        -javaagent:/stackable/jmx/jmx_prometheus_javaagent.jar=8081:/stackable/jmx-exporter-config/journalnode.yaml
        -Xmx419430k
    podOverrides:
      spec:
        containers:
          - name: journalnode
            volumeMounts:
              - name: jmx-exporter-config
                mountPath: /stackable/jmx-exporter-config
        volumes:
          - name: jmx-exporter-config
            configMap:
              name: jmx-exporter-config
    config:
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
    roleGroups:
      default:
        envOverrides:
          COMMON_VAR: group-value # overrides role value
          GROUP_VAR: group-value # only defined here at group level
        replicas: 1
        podOverrides:
          spec:
            containers:
              - name: journalnode
                resources:
                  requests:
                    cpu: 110m
                  limits:
                    cpu: 410m
                ports:
                  # https://github.com/stackabletech/hdfs-operator/issues/514
                  - name: dashed-port
                    containerPort: 1234
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: jmx-exporter-config
data:
  namenode.yaml: |-
    ---
    startDelaySeconds: 10
    ssl: false
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    whitelistObjectNames:
      - 'Hadoop:service=NameNode,name=*'
      - 'Hadoop:service=NameNode,name=MetricsSystem,sub=*'
    blacklistObjectNames:
      - 'Hadoop:service=NameNode,name=RetryCache.NameNodeRetryCache'
      - 'Hadoop:service=NameNode,name=RpcActivity*'
      - 'Hadoop:service=NameNode,name=RpcDetailedActivity*'
      - 'Hadoop:service=NameNode,name=UgiMetrics'
    rules:
      # MetricsSystem
      - pattern: 'Hadoop<service=(.*), name=MetricsSystem, sub=(.*)><>(.*): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: 'MetricsSystem'
          sub: $2
        type: GAUGE
      # Total raw capacity in bytes, e.g. Hadoop:name=NameNodeInfo,attribute=Total
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(total): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: COUNTER
      # Generic counter, e.g. Hadoop:name=FSNamesystem,attribute=FilesTotal
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*_total): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: COUNTER
      # Metrics suffixed with _created, e.g. Hadoop:name=NameNodeActivity,attribute=FilesCreated
      # The suffix _created is reserved for timestamps, therefore an underscore is appended.
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*_created): (.*)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3_
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: GAUGE
      # Metrics suffixed with _info, e.g. Hadoop:name=JvmMetrics,attribute=LogInfo
      # The suffix _info is reserved for static information, therefore an underscore is appended.
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*_info): (.*)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3_
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: GAUGE
      # All other Hadoop metrics
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*): (.*)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: GAUGE
  datanode.yaml: |-
    ---
    startDelaySeconds: 10
    ssl: false
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    whitelistObjectNames:
      - 'Hadoop:service=DataNode,name=*'
      - 'Hadoop:service=DataNode,name=MetricsSystem,sub=*'
    blacklistObjectNames:
      - 'Hadoop:service=DataNode,name=RpcActivity*'
      - 'Hadoop:service=DataNode,name=RpcDetailedActivity*'
      - 'Hadoop:service=DataNode,name=UgiMetrics'
    rules:
      # MetricsSystem
      - pattern: 'Hadoop<service=(.*), name=MetricsSystem, sub=(.*)><>(.*): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: 'MetricsSystem'
          sub: $2
        type: GAUGE
      # FSDatasetState with _total suffix (also extracts the FSDataset ID),
      # e.g. Hadoop:name=FSDatasetState,attribute=EstimatedCapacityLostTotal
      - pattern: 'Hadoop<service=(.*), name=FSDatasetState-(.*)><>(.*_total): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          fsdatasetid: $2
          kind: 'FSDatasetState'
        type: COUNTER
      # FSDatasetState (also extracts the FSDataset ID)
      - pattern: 'Hadoop<service=(.*), name=FSDatasetState-(.*)><>(.*): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          fsdatasetid: $2
          kind: 'FSDatasetState'
        type: GAUGE
      # DataNodeActivity with _info suffix (also extracts hostname and port),
      # e.g. Hadoop:name=DataNodeActivity-hdfs-datanode-default-0-9866,attribute=BlocksGetLocalPathInfo
      - pattern: 'Hadoop<service=(.*), name=DataNodeActivity-(.*)-(\d+)><>(.*_info): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$4_
        value: $5
        labels:
          service: HDFS
          role: $1
          host: $2
          port: $3
          kind: 'DataNodeActivity'
        type: GAUGE
      - pattern: 'Hadoop<service=(.*), name=DataNodeActivity-(.*)-(\d+)><>(.*): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$4
        value: $5
        labels:
          service: HDFS
          role: $1
          host: $2
          port: $3
          kind: 'DataNodeActivity'
        type: GAUGE
      # Generic counter, e.g. Hadoop:name=FSDatasetState,attribute=EstimatedCapacityLostTotal
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*_total): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: COUNTER
      # Metrics suffixed with _info, e.g. Hadoop:name=JvmMetrics,attribute=LogInfo
      # The suffix _info is reserved for static information, therefore an underscore is appended.
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*_info): (.*)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3_
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: GAUGE
      # All other Hadoop metrics
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*): (.*)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: GAUGE
  journalnode.yaml: |-
    ---
    startDelaySeconds: 10
    ssl: false
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    whitelistObjectNames:
      - 'Hadoop:service=JournalNode,name=*'
      - 'Hadoop:service=JournalNode,name=MetricsSystem,sub=*'
    blacklistObjectNames:
      - 'Hadoop:service=JournalNode,name=RetryCache.JournalNodeRetryCache'
      - 'Hadoop:service=JournalNode,name=RpcActivity*'
      - 'Hadoop:service=JournalNode,name=RpcDetailedActivity*'
      - 'Hadoop:service=JournalNode,name=UgiMetrics'
    rules:
      # MetricsSystem
      - pattern: 'Hadoop<service=(.*), name=MetricsSystem, sub=(.*)><>(.*): (\d+)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: 'MetricsSystem'
          sub: $2
        type: GAUGE
      # Metrics suffixed with _info, e.g. Hadoop:name=JvmMetrics,attribute=LogInfo
      # The suffix _info is reserved for static information, therefore an underscore is appended.
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*_info): (.*)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3_
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: GAUGE
      # All other Hadoop metrics
      - pattern: 'Hadoop<service=(.*), name=(.*)><>(.*): (.*)'
        attrNameSnakeCase: true
        name: hadoop_$1_$3
        value: $4
        labels:
          service: HDFS
          role: $1
          kind: $2
        type: GAUGE
