---
apiVersion: kuttl.dev/v1beta1
kind: TestStep
metadata:
  name: install-hdfs
timeout: 180
---
apiVersion: hdfs.stackable.tech/v1alpha1
kind: HdfsCluster
metadata:
  name: hdfs
spec:
  image:
    productVersion: "{{ test_scenario['values']['hadoop'].split('-stackable')[0] }}"
    stackableVersion: "{{ test_scenario['values']['hadoop'].split('-stackable')[1] }}"
  clusterConfig:
    zookeeperConfigMapName: hdfs-zk
    dfsReplication: 1
    listenerClass: {{ test_scenario['values']['listener-class'] }}
{% if lookup('env', 'VECTOR_AGGREGATOR') %}
    vectorAggregatorConfigMapName: vector-aggregator-discovery
{% endif %}
  nameNodes:
    config:
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
    roleGroups:
      default:
        replicas: 2
  dataNodes:
    config:
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
{% if test_scenario['values']['datanode-pvcs'] == '2hdd-1ssd' %}
      resources:
        storage:
          data: # We need to overwrite the data pvcs coming from the default value
            count: 0
          hdd:
            capacity: 2Gi
            count: 2
            hdfsStorageType: Disk
          ssd:
            capacity: 1Gi
            # storageClass: premium # We can't set the storage class in itegration tests, as we don't know which ones are available
            count: 1
            hdfsStorageType: SSD
{% endif %}
    roleGroups:
      default:
        replicas: {{ test_scenario['values']['number-of-datanodes'] }}
  journalNodes:
    config:
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
    roleGroups:
      default:
        replicas: 1
        podOverrides:
          spec:
            containers:
              - name: journalnode
                resources:
                  requests:
                    cpu: 110m
                  limits:
                    cpu: 410m
