---
apiVersion: kuttl.dev/v1beta1
kind: TestStep
metadata:
  name: install-hdfs
timeout: 180
---
apiVersion: hdfs.stackable.tech/v1alpha1
kind: HdfsCluster
metadata:
  name: hdfs
spec:
  image:
    productVersion: "{{ test_scenario['values']['hadoop'].split('-stackable')[0] }}"
    stackableVersion: "{{ test_scenario['values']['hadoop'].split('-stackable')[1] }}"
  zookeeperConfigMapName: hdfs-zk
{% if lookup('env', 'VECTOR_AGGREGATOR') %}
  vectorAggregatorConfigMapName: vector-aggregator-discovery
{% endif %}
  dfsReplication: 1
  nameNodes:
    config:
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
      resources:
        cpu:
          max: '1'
          min: '300m'
        memory:
          limit: '512Mi'
    roleGroups:
      default:
        replicas: 2
  dataNodes:
    config:
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
      resources:
        cpu:
          max: '1'
          min: '300m'
        memory:
          limit: '512Mi'
{% if test_scenario['values']['datanode-pvcs'] == '2hdd-1ssd' %}
        storage:
          data: # We need to overwrite the data pvcs coming from the default value
            count: 0
          hdd:
            capacity: 2Gi
            count: 2
            hdfsStorageType: Disk
          ssd:
            capacity: 1Gi
            # storageClass: premium # We can't set the storage class in itegration tests, as we don't know which ones are available
            count: 1
            hdfsStorageType: SSD
{% endif %}
    roleGroups:
      default:
        replicas: {{ test_scenario['values']['number-of-datanodes'] }}
  journalNodes:
    config:
      logging:
        enableVectorAgent: {{ lookup('env', 'VECTOR_AGGREGATOR') | length > 0 }}
      resources:
        cpu:
          max: '1'
          min: '300m'
        memory:
          limit: '512Mi'
    roleGroups:
      default:
        replicas: 1
